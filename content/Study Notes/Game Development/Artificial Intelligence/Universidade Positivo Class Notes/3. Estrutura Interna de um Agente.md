#Teaching #AIGameDev #AI #ArtificialIntelligence #GameDevelopment #SmartAgents

O trabalho de um programador de IA é criar um programa agente que implementa uma função agente que mapeia as percepções em ações. Assumimos em jogos que os agentes irão atuar em um ambiente virtual com sensores e atuadores, ou seja, ele tem uma arquitetura bem definida. Por motivos óbvios é necessária que a arquitetura e o agente sejam compatíveis, por exemplo, se é necessário que um inimigo faça uma patrulha entre dois pontos é necessário que ele tenha sensores representando seus “olhos” e “ouvidos”.

A grande maioria dos programas agente tem a seguinte estrutura: percebem o estado atual do ambiente através do sensores e retornam uma ação através dos atuadores. Observe que existe uma diferença entre percepção do estado atual e a função agente que pode considerar todo o histórico de percepções. 
![[Pasted image 20240502013944.png]]

É possível construir o pseudo código a partir dessa estrutura básica:
![[Pasted image 20240502014003.png]]
Observe que esse agente considera que existe uma tabela que mapeia diretamente percepções nas ações tomadas. Essa não é uma abordagem muito interessante já que escalona muito mal. Considere P o conjunto de percepções possíveis e T o tempo de vida total do agente A tabela portanto vai conter:
![[Pasted image 20240502014022.png]]

Considerando um táxi autônomo que utiliza apenas uma câmera como sensor. Considere então que essa câmera grava 27 mB de informação por segundo (30 frames 640x480 pixels com 24 bits de informação). Para apenas 1 hora de direção deste táxi são necessárias 10250 000 000 000 entradas nesta tabela. Mesmo considerando se essa tabela fosse construída para um ambiente mais simples e bem comportado como um jogo de xadrez seriam necessárias 10150 entradas. Portanto, apesar de ser uma solução simples de ser implementada, computacionalmente é impossível de ser implementada em ambientes mais complexos por dois motivos:

- Nenhum agente seria capaz de armazenar essa tabela.
    
- É impossível para um ser humano criar todas essas entradas.
    

Entretanto, esse agente baseado em tabela faz o que é desejado já que implementa uma função agente.

# Tipos de Agente

Existem 4 tipos básicos de programas agentes que englobam quase todos os sistemas inteligentes: Agentes de Reflexo Simples, Agentes Baseados em Modelos, Agentes Orientados a Objetivos e Agentes Baseados em Utilidade.

## Agentes de Reflexo Simples

O tipo mais comum de agente em jogos é o de reflexo simples. Esses agentes buscam selecionar ações baseando-se na percepção atual e ignorando todo o resto do histórico de percepções. É bastante comum a utilização deste tipo de agentes para criar agentes em jogos. Como exemplo clássico de um agente de reflexo simples temos o [“Dark Link”](https://www.youtube.com/watch?v=4ojBO_Yj9Js) em Ocarina of Time. Isso se deve ao fato de que a implementação destes agentes é bastante simples e com uma inteligência artificial bastante limitada. Ou seja, um agente de reflexo simples não é muito “selvagem”.

A estrutura do programa agente deste tipo de agentes pode ser vista a seguir:
![[Pasted image 20240502014049.png]]

O pseudocódigo de um agente de reflexo simples que age de acordo com as condições percebidas do estado atual do ambiente pode ser descrito da seguinte forma:
![[Pasted image 20240502014103.png]]

Observe que um agente utilizando essa implementação irá funcionar apenas se a decisão correta puder ser feita baseando-se na percepção atual do ambiente, mesmo que o ambiente seja completamente observável. Essa característica pode levar a loops-infinitos e é possível fugir dessa situação se o agente randomizar suas ações, aumentando assim a imprevisibilidade do agente.

## Agentes Baseados em Modelos

Uma maneira bastante eficiente de resolver problemas causados pela parcialidade de observação de um ambiente é manter um conjunto de informações sobre o que não é observável em determinado instante. Esse agente deve manter um estado interno que depende do histórico de percepções e que reflete de certa forma parte do ambiente não observável.

Para a construção desse estado interno é necessário dois tipos de conhecimento sobre o agente. É preciso saber como esse ambiente reage quando o agente não está presente e como as ações do agente influenciam o ambiente. A partir  desses conhecimentos é possível a construção de um modelo. A estrutura básica de um agente baseado em modelos pode ser observada a seguir:
![[Pasted image 20240502014213.png]]

Destaca-se que normalmente é impossível determinar o estado do ambiente com exatidão. Portanto a caixa com o nome “What the world is like now” é o melhor “chute” feito pelo agente. 

O pseudocódigo de um agente baseado em modelos também é simples de ser compreendido, porém a dificuldade de implementação está na manutenção e no detalhamento necessário do modelo. Como é possível observar a seguir:
![[Pasted image 20240502014232.png]]

## Agente Orientado a Objetivos

Em algumas situações saber o estado atual de um ambiente não é suficiente, é necessário ter um objetivo final desta IA. Portanto, o agente necessita além do modelo, ele também precisa de informações sobre situações que são desejáveis. Em algumas situações esse objetivo é direto, por exemplo, situações em que basta apenas uma ação para obter o objetivo desejado. Entretanto, na grande maioria dos casos é necessário considerar uma sequência de ações para se obter o objetivo, portanto, é necessário buscar e planejar essa sequência de ações. Este também é um tipo de agente comumente utilizado em jogos. O jogo F.E.A.R utiliza este tipo de agentes. A figura a seguir mostra a estrutura interna de um agente orientado a objetivos:

![[Pasted image 20240502014252.png]]

## Agente Baseados em Utilidade

Em algumas situações saber o estado é desejado ou não é insuficiente. Observe que os objetivos apenas uma distinção binária entre estados desejados e indesejados. Na grande maioria das situações é necessário determinar o quão desejado ou indesejado é um estado. A função que determina esse valor é chamada de utilidade. Essa função utilidade é essencialmente uma forma interna de determinar a performance de um agente no ambiente. Se os valores retornados pela função utilidade interna forem iguais as medidas de performance externas, então o agente que escolhe ações que maximizem o valor da função utilidade agem de forma racional.

Os agentes baseados em utilidade se demonstram inadequados em duas situações, mas ainda são capazes de tomarem decisões racionais: quando existem objetivos conflitantes ou quando há um conjunto de objetivos que o agente pode alcançar, porém sem certeza de nenhum deles. A estrutura interna de um agente baseado em utilidade é apresentada a seguir:

![[Pasted image 20240502014339.png]]